import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from predictor import predict_sentiment, load_model_components
import datetime
import underthesea
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import xgboost
import joblib
from tqdm import tqdm
import requests

st.set_page_config(layout="wide")
st.title("H·ªá th·ªëng Ph√¢n t√≠ch & ƒê·ªÅ xu·∫•t Doanh nghi·ªáp IT")

# --- CSS ƒë·ªÉ c·ªë ƒë·ªãnh th√¥ng tin l·ªõp/h·ªçc vi√™n ·ªü cu·ªëi sidebar ---
st.markdown("""
<style>
    .st-emotion-cache-vk3305 { /* ƒê√¢y l√† class c·ªßa sidebar ch√≠nh */
        display: flex;
        flex-direction: column;
        justify-content: space-between; /* ƒê·∫©y n·ªôi dung l√™n tr√™n v√† xu·ªëng d∆∞·ªõi */
    }
    .fixed-bottom-left {
        position: sticky; /* Ho·∫∑c fixed n·∫øu b·∫°n mu·ªën n√≥ lu√¥n ·ªü ƒë√≥ ngay c·∫£ khi cu·ªôn */
        bottom: 0;
        left: 0; /* ƒê·∫£m b·∫£o n√≥ n·∫±m s√°t m√©p tr√°i c·ªßa sidebar */
        width: 100%; /* Chi·∫øm to√†n b·ªô chi·ªÅu r·ªông c·ªßa sidebar */
        padding: 1rem; /* Th√™m padding cho ƒë·∫πp */
        background-color: #f0f2f6; /* M√†u n·ªÅn gi·ªëng sidebar ho·∫∑c m√†u b·∫°n mu·ªën */
        border-top: 1px solid #e0e0e0; /* ƒê∆∞·ªùng vi·ªÅn ph√≠a tr√™n ƒë·ªÉ t√°ch bi·ªát */
        box-sizing: border-box; /* ƒê·∫£m b·∫£o padding kh√¥ng l√†m tƒÉng k√≠ch th∆∞·ªõc */
        font-size: 0.95rem;
        z-index: 100;
    }
</style>
""", unsafe_allow_html=True)

# --- Sidebar: Logo, Menu v√† Th√¥ng tin h·ªçc vi√™n ---
with st.sidebar:
    st.image("img/your_logo.jpg", width=60)
    st.markdown("<h3 style='margin-bottom:0.5rem;'>IT Recommendation System</h3>", unsafe_allow_html=True)

    menu_options = {
        "Business Problem": "üíº Ph√¢n t√≠ch nghi·ªáp v·ª•",
        "Build Project": "üõ†Ô∏è X√¢y d·ª±ng m√¥ h√¨nh",
        "New Prediction": "üìä Ph√¢n t√≠ch c√¥ng ty"
    }
    menu_labels = list(menu_options.values())
    menu_keys = list(menu_options.keys())

    # Kh√¥ng c·∫ßn index, ch·ªâ l·∫•y m·∫∑c ƒë·ªãnh l√† 0
    selected_label = st.selectbox(
        "Menu",
        menu_labels,
        index=0
    )
    # L·∫•y key th·ª±c t·∫ø t·ª´ label
    menu_selection = menu_keys[menu_labels.index(selected_label)]

    # Highlight m·ª•c ƒëang ch·ªçn (CSS)
    st.markdown("""
    <style>
    .stSelectbox [data-baseweb="select"] > div {
        font-weight: bold;
        background: #e6f0ff;
    }
    </style>
    """, unsafe_allow_html=True)

    st.markdown(
        """
        <div class="fixed-bottom-left" style="background-color:#f0f2f6; border-top:1px solid #e0e0e0;">
        <b>L·ªöP DL07_K304 - DATA SCIENCE - MACHINE LEARNING</b><br>
        H·ªçc vi√™n th·ª±c hi·ªán:<br>
        - <b>Ms. Giang Phi Y·∫øn</b> - <a href='mailto:yengp96@gmail.com'>Email</a><br>
        - <b>Ms. Nguy·ªÖn Ng·ªçc Kh√°nh Linh</b> - <a href='mailto:nnkl1517000@gmail.com'>Email</a>
        </div>
        """,
        unsafe_allow_html=True
    )

# --- 1. Business Problem ---
if menu_selection == "Business Problem":
    st.header("Hi·ªÉu r√µ V·∫•n ƒë·ªÅ Kinh doanh")
    st.markdown("""
    ·ª®ng d·ª•ng n√†y nh·∫±m gi·∫£i quy·∫øt hai v·∫•n ƒë·ªÅ c·ªët l√µi trong lƒ©nh v·ª±c tuy·ªÉn d·ª•ng v√† ƒë√°nh gi√° doanh nghi·ªáp IT t·∫°i Vi·ªát Nam.
    Ch√∫ng t√¥i s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ n·ªÅn t·∫£ng tuy·ªÉn d·ª•ng **ITviec.com** ƒë·ªÉ cung c·∫•p c√°c ph√¢n t√≠ch v√† d·ª± ƒëo√°n h·ªØu √≠ch nh·∫±m h·ªó tr·ª£ c√¥ng ty v√† ng∆∞·ªùi lao ƒë·ªông.
    """)

    st.subheader("1.1. Ph√¢n t√≠ch C·∫£m x√∫c t·ª´ Review (Sentiment Analysis)")
    st.markdown("""
    * **Y√™u c·∫ßu:** Ph√¢n t√≠ch c√°c ƒë√°nh gi√° (review) ƒë∆∞·ª£c ƒëƒÉng b·ªüi ·ª©ng vi√™n ho·∫∑c nh√¢n vi√™n v·ªÅ c√°c c√¥ng ty tr√™n n·ªÅn t·∫£ng **ITviec**.
    * **Ngu·ªìn d·ªØ li·ªáu:** Bao g·ªìm c√°c tr∆∞·ªùng nh∆∞ n·ªôi dung t√≠ch c·ª±c, g√≥p √Ω c·∫£i thi·ªán, ƒëi·ªÉm ƒë√°nh gi√°...
    * **M·ª•c ti√™u:** D·ª± ƒëo√°n c·∫£m x√∫c t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng review (t√≠ch c·ª±c / ti√™u c·ª±c / trung t√≠nh). K·∫øt qu·∫£ n√†y h·ªó tr·ª£ c√°c c√¥ng ty:
        - Theo d√µi ph·∫£n h·ªìi t·ª´ nh√¢n vi√™n/·ª©ng vi√™n.
        - Ph·∫£n ·ª©ng nhanh v·ªõi c√°c v·∫•n ƒë·ªÅ n·ªôi b·ªô.
        - C·∫£i thi·ªán h√¨nh ·∫£nh th∆∞∆°ng hi·ªáu nh√† tuy·ªÉn d·ª•ng.
    """)
    st.info("üí° B·∫°n c√≥ th·ªÉ tr·∫£i nghi·ªám ph√¢n t√≠ch n√†y trong ph·∫ßn 'Build Project' v√† d·ª± ƒëo√°n nhanh t·∫°i 'New Prediction'.")

    st.subheader("1.2. Ph√¢n C·ª•m Th√¥ng Tin ƒê√°nh Gi√° (Information Clustering)")
    st.markdown("""
    * **Y√™u c·∫ßu:** D·ª±a tr√™n n·ªôi dung review ƒë·ªÉ ph√¢n lo·∫°i nh√≥m ƒë√°nh gi√° m√† c√¥ng ty ƒëang thu·ªôc v·ªÅ.
    * **Ngu·ªìn d·ªØ li·ªáu:** VƒÉn b·∫£n ƒë√°nh gi√° t·ª´ nhi·ªÅu c√¥ng ty tr√™n ITviec.
    * **M·ª•c ti√™u:** Gi√∫p c√¥ng ty hi·ªÉu ƒë∆∞·ª£c b·∫£n th√¢n ƒëang n·∫±m trong nh√≥m n√†o (v√≠ d·ª•: nh√≥m b·ªã ch√™ qu·∫£n l√Ω ‚Äì nh√≥m n·ªïi b·∫≠t v·ªÅ ƒë√†o t·∫°o ‚Äì nh√≥m c√≥ ch√≠nh s√°ch t·ªët...).
        - So s√°nh v·ªõi ƒë·ªëi th·ªß c√πng ng√†nh.
        - X√°c ƒë·ªãnh nh√≥m ƒëi·ªÉm m·∫°nh v√† y·∫øu ƒë·ªÉ ∆∞u ti√™n c·∫£i thi·ªán.
    """)
    st.info("üí° B·∫°n c√≥ th·ªÉ xem c·ª• th·ªÉ t·ª´ng nh√≥m/c·ª•m ph√¢n t√≠ch trong ph·∫ßn 'Build Project'.")

# --- 2. Build Project ---
elif menu_selection == "Build Project":
    st.header("2. Build Project (Data Science Pipeline)")
    tabs_build = st.tabs([
        "Business Understanding",
        "Data Understanding",
        "Data Preparation",
        "Modeling",
        "Evaluation",
        "Deployment"
    ])

    with tabs_build[0]:
        st.subheader("B∆∞·ªõc 1: Hi·ªÉu b√†i to√°n (Business Understanding)")
        st.markdown("""
        - **M·ª•c ti√™u 1:** D·ª± ƒëo√°n c·∫£m x√∫c review.
        - **M·ª•c ti√™u 2:** Ph√¢n c·ª•m n·ªôi dung ƒë√°nh gi√°.
        """)

    with tabs_build[1]:
        st.subheader("B∆∞·ªõc 2: Kh√°m ph√° v√† ch·ªçn l·ªçc d·ªØ li·ªáu (Data Understanding)")
        st.markdown("""
        - Cho ph√©p ch·ªçn c√¥ng ty c·ª• th·ªÉ ƒë·ªÉ ph√¢n t√≠ch.
        - Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng review, th·ªùi gian, ƒëi·ªÉm ƒë√°nh gi√°, v.v.
        """)
        st.markdown("""
        ---
        **D·ªØ li·ªáu ƒë·∫ßu v√†o s·ª≠ d·ª•ng cho ph√¢n t√≠ch g·ªìm 3 t·ªáp ch√≠nh:**

        1. **Overview_Companies.xlsx**
            - Th√¥ng tin t·ªïng quan v·ªÅ c√°c c√¥ng ty.

        2. **Overview_Reviews.xlsx**
            - Th·ªëng k√™ ƒëi·ªÉm ƒë√°nh gi√° t·ªïng quan c·ªßa m·ªói c√¥ng ty.
            - *M·ª•c ƒë√≠ch s·ª≠ d·ª•ng:* Ph√¢n t√≠ch t·ªïng h·ª£p c√¥ng ty, ƒë√°nh gi√° t·ªïng th·ªÉ theo chi·ªÅu r·ªông (x√°c ƒë·ªãnh c√¥ng ty n√†o t·ªët/x·∫•u).

        3. **Reviews.xlsx**
            - N·ªôi dung review chi ti·∫øt t·ª´ ng∆∞·ªùi d√πng.
            - *ƒê·∫∑c ƒëi·ªÉm:* Tr√≠ch xu·∫•t c·∫£m x√∫c (t·ª´ c√°c ph·∫ßn nh∆∞ "What I liked", "Suggestions"...).
            - *M·ª•c ƒë√≠ch s·ª≠ d·ª•ng:* D√πng cho m√¥ h√¨nh ph√¢n c·ª•m (clustering), LDA (Latent Dirichlet Allocation), wordcloud.
            - *Vai tr√≤:* L√† ngu·ªìn ƒë·∫ßu v√†o ch√≠nh cho h·∫ßu h·∫øt c√°c ph√¢n t√≠ch.
        """)

    with tabs_build[2]:
        st.subheader("B∆∞·ªõc 3: Chu·∫©n b·ªã d·ªØ li·ªáu (Data Preparation)")
        st.markdown("""
        - Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n: x√≥a stopwords, chu·∫©n h√≥a ti·∫øng Vi·ªát, tokenize (s·ª≠ d·ª•ng Underthesea).
        - TF-IDF ho·∫∑c CountVectorizer cho feature extraction.
        """)

    with tabs_build[3]:
        st.subheader("B∆∞·ªõc 4: Modeling")
        st.markdown("""
        - **Sentiment Analysis:** XGBoost/ Logistic Regression / RandomForest / SVM / Naive Bayes/ K-Nearest Neighbors  
        ‚Üí *M√¥ h√¨nh XGBoost l√† m√¥ h√¨nh c√≥ hi·ªáu su·∫•t cao nh·∫•t v·ªÅ t·∫•t c·∫£ c√°c ti√™u ch√≠.*
        - **Clustering:** KMeans / Agglomerative / DBSCAN + LDA (g·ª£i √Ω s·ªë c·ª•m).  
        ‚Üí *M√¥ h√¨nh LDA + KMeans t·ªët nh·∫•t - Hi·ªáu qu·∫£ nh·∫•t, tr·ª±c quan ƒë·∫πp, d·ªÖ di·ªÖn gi·∫£i.*
        """)

    with tabs_build[4]:
        st.subheader("B∆∞·ªõc 5: Evaluation")
        st.markdown("""
        - ƒê√°nh gi√° ph√¢n lo·∫°i: accuracy, precision, recall, F1, confusion matrix, ROC curve.
        - ƒê√°nh gi√° clustering: Silhouette score, bi·ªÉu ƒë·ªì t∆∞·ªùng minh c·ª•m.
        """)

    with tabs_build[5]:
        st.subheader("B∆∞·ªõc 6: Deployment")
        st.markdown("""
        - Hi·ªÉn th·ªã dashboard ph√¢n t√≠ch cho t·ª´ng c√¥ng ty:
            - Wordcloud t√≠ch c·ª±c / ti√™u c·ª±c
            - T·ª´ kh√≥a n·ªïi b·∫≠t
            - C·ª•m th√¥ng tin m√† c√¥ng ty thu·ªôc v·ªÅ
            - G·ª£i √Ω c·∫£i thi·ªán
        """)

# --- 3. New Prediction ---
elif menu_selection == "New Prediction":
    st.header("üìä Ph√¢n t√≠ch C√¥ng ty C·ª• th·ªÉ t·ª´ Review")

    # Tab ƒë·ªÉ t√°ch bi·ªát c√°c ch·ª©c nƒÉng
    tab1, tab2 = st.tabs([
        "üè¢ T·ªïng quan c√¥ng ty", 
        "üîé Ph√¢n t√≠ch c·∫£m x√∫c m·ªõi"
    ])

    with tab1:
        # 1. Ch·ªçn c√¥ng ty
        with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
            df = pd.read_excel("output/Processed_reviews.xlsx")

        # B·ªô l·ªçc th·ªùi gian n·∫øu c√≥ c·ªôt ng√†y
        if "Review Date" in df.columns:
            df["Review Date"] = pd.to_datetime(df["Review Date"])
            min_date = df["Review Date"].min()
            max_date = df["Review Date"].max()
            date_range = st.slider(
                "Ch·ªçn kho·∫£ng th·ªùi gian",
                min_value=min_date,
                max_value=max_date,
                value=(min_date, max_date),
                format="DD/MM/YYYY"
            )
            with st.spinner("ƒêang l·ªçc d·ªØ li·ªáu theo th·ªùi gian..."):
                df = df[(df["Review Date"] >= date_range[0]) & (df["Review Date"] <= date_range[1])]

        company = st.selectbox("Ch·ªçn c√¥ng ty ƒë·ªÉ ph√¢n t√≠ch", df["Company Name"].dropna().unique())
        company_df = df[df["Company Name"] == company]

        # 2. Th·ªëng k√™ c∆° b·∫£n
        st.markdown("### 1Ô∏è‚É£ T·ªïng quan ƒë√°nh gi√°")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("T·ªïng s·ªë review", len(company_df))
            st.metric("ƒêi·ªÉm ƒë√°nh gi√° trung b√¨nh", f"{company_df['Rating'].mean():.2f}")
            st.write("**Ph√¢n b·ªë c·∫£m x√∫c:**")
            sentiment_counts = company_df["sentiment"].value_counts()
            st.bar_chart(sentiment_counts)
            st.write("**Nh·∫≠n x√©t t√≠ch c·ª±c n·ªïi b·∫≠t:**")
            st.write(company_df[company_df["sentiment"] == "positive"]["What I liked"].dropna().head(3).tolist())
            st.write("**Nh·∫≠n x√©t ti√™u c·ª±c n·ªïi b·∫≠t:**")
            st.write(company_df[company_df["sentiment"] == "negative"]["Suggestions for improvement"].dropna().head(3).tolist())
            # Hi·ªÉn th·ªã c·ª•m m√† c√¥ng ty thu·ªôc v·ªÅ
            if "cluster" in company_df.columns:
                cluster_id = company_df["cluster"].mode().values[0]
                st.write(f"**C√¥ng ty n√†y thu·ªôc c·ª•m ƒë√°nh gi√° s·ªë:** `{cluster_id}`")
                # ƒê·ªÅ xu·∫•t c·∫£i thi·ªán d·ª±a tr√™n c·ª•m
                st.info(f"‚Üí ƒê·ªÅ xu·∫•t: Tham kh·∫£o c√°c c√¥ng ty c√πng c·ª•m {cluster_id} ƒë·ªÉ c·∫£i thi·ªán ƒëi·ªÉm y·∫øu v√† ph√°t huy ƒëi·ªÉm m·∫°nh.")
        with col2:
            st.subheader("WordCloud t√≠ch c·ª±c")
            pos_text = " ".join(company_df[company_df['sentiment'] == 'positive']['liked_clean'].dropna())
            if pos_text:
                wc = WordCloud(width=400, height=200, background_color="white").generate(pos_text)
                fig, ax = plt.subplots(figsize=(6, 3))
                ax.imshow(wc, interpolation='bilinear')
                ax.axis("off")
                st.pyplot(fig)
            st.subheader("WordCloud ti√™u c·ª±c")
            neg_text = " ".join(company_df[company_df['sentiment'] == 'negative']['suggestion_clean'].dropna())
            if neg_text:
                wc = WordCloud(width=400, height=200, background_color="white").generate(neg_text)
                fig, ax = plt.subplots(figsize=(6, 3))
                ax.imshow(wc, interpolation='bilinear')
                ax.axis("off")
                st.pyplot(fig)

        # Tr·ª±c quan h√≥a ph√¢n c·ª•m n·∫øu c√≥ d·ªØ li·ªáu
        if {'x', 'y', 'cluster'}.issubset(company_df.columns):
            st.subheader("Ph√¢n c·ª•m ƒë√°nh gi√° (KMeans)")
            fig, ax = plt.subplots(figsize=(6, 4))
            sns.scatterplot(data=company_df, x="x", y="y", hue="cluster", palette="Set2", ax=ax)
            st.pyplot(fig)

        # 3. Nh·∫≠n x√©t n·ªïi b·∫≠t
        st.markdown("### 2Ô∏è‚É£ Nh·∫≠n x√©t ti√™u bi·ªÉu")

        # Ch·ªçn c·∫£m x√∫c ƒë·ªÉ xem chi ti·∫øt review
        sentiment_labels = []
        sentiment_counts = company_df["sentiment"].value_counts()
        sentiment_perc = sentiment_counts / sentiment_counts.sum() * 100
        for sentiment in sentiment_counts.index:
            count = sentiment_counts[sentiment]
            perc = sentiment_perc[sentiment]
            sentiment_labels.append(f"{sentiment} ({count} reviews, {perc:.1f}%)")
        sentiment_map = dict(zip(sentiment_labels, sentiment_counts.index))
        selected_sentiment = st.radio(
            "Ch·ªçn c·∫£m x√∫c ƒë·ªÉ xem chi ti·∫øt review:",
            sentiment_labels,
            horizontal=True
        )
        chosen_sentiment = sentiment_map[selected_sentiment]

        # B·∫£ng k·∫øt qu·∫£ review theo c·∫£m x√∫c ƒë√£ ch·ªçn
        st.markdown(f"**Danh s√°ch review v·ªõi c·∫£m x√∫c: _{chosen_sentiment}_**")
        review_cols = ["What I liked", "Suggestions for improvement", "Rating"]
        if "Review Date" in company_df.columns:
            review_cols = ["Review Date"] + review_cols
        st.dataframe(
            company_df[company_df["sentiment"] == chosen_sentiment][review_cols].reset_index(drop=True)
        )

        # 5. Ph√¢n c·ª•m
        if {"x", "y", "cluster"}.issubset(company_df.columns):
            st.markdown("### 4Ô∏è‚É£ Ph√¢n c·ª•m th√¥ng tin ƒë√°nh gi√° (KMeans)")
            fig, ax = plt.subplots()
            sns.scatterplot(data=company_df, x="x", y="y", hue="cluster", palette="Set2", ax=ax)
            ax.set_title("Bi·ªÉu ƒë·ªì ph√¢n c·ª•m review")
            st.pyplot(fig)

            st.markdown("**Th√¥ng tin theo c·ª•m**:")
            for cluster_id in sorted(company_df["cluster"].unique()):
                st.markdown(f"#### üî∏ C·ª•m {cluster_id}")
                cluster_reviews = company_df[company_df["cluster"] == cluster_id]
                st.write("**T·ª´ kh√≥a ch√≠nh:**")
                keyword_cluster = " ".join(cluster_reviews["liked_clean"].fillna("") + " " + cluster_reviews["suggestion_clean"].fillna(""))
                if keyword_cluster:
                    wordcloud = WordCloud(width=600, height=200).generate(keyword_cluster)
                    fig, ax = plt.subplots()
                    ax.imshow(wordcloud, interpolation="bilinear")
                    ax.axis("off")
                    st.pyplot(fig)
                st.caption(f"T·ªïng s·ªë review trong c·ª•m: {len(cluster_reviews)}")

        # 6. ƒê·ªÅ xu·∫•t t·ªïng h·ª£p
        st.markdown("### 5Ô∏è‚É£ ƒê·ªÅ xu·∫•t c·∫£i thi·ªán cho c√¥ng ty")
        if company_df["sentiment"].value_counts().get("negative", 0) > company_df["sentiment"].value_counts().get("positive", 0):
            st.warning("C√¥ng ty ƒëang nh·∫≠n nhi·ªÅu review ti√™u c·ª±c h∆°n t√≠ch c·ª±c. N√™n t·∫≠p trung c·∫£i thi·ªán c√°c v·∫•n ƒë·ªÅ sau:")
        else:
            st.success("C√¥ng ty nh·∫≠n nhi·ªÅu ƒë√°nh gi√° t√≠ch c·ª±c. Tuy nhi√™n v·∫´n c√≥ th·ªÉ c·∫£i thi·ªán th√™m nh·ªØng ƒëi·ªÉm sau:")

        suggestions = company_df["Suggestions for improvement"].dropna().head(5).tolist()
        for s in suggestions:
            st.markdown(f"- {s}")

    with tab2:
        try:
            # Load model v√† vectorizer ƒë√£ hu·∫•n luy·ªán
            xgb_model = joblib.load("models/sentiment_model.pkl")
            vectorizer = joblib.load("models/tfidf_vectorizer.pkl")
            label_encoder = joblib.load("models/label_encoder.pkl")

            st.header("üìù Ph√¢n t√≠ch c·∫£m x√∫c & ph√¢n c·ª•m cho review m·ªõi")

            # 1. Nh·∫≠p d·ªØ li·ªáu m·ªõi
            input_method = st.radio("Ch·ªçn c√°ch nh·∫≠p d·ªØ li·ªáu:", ["‚úçÔ∏è Nh·∫≠p tay", "üìÅ T·∫£i file Excel"])

            if input_method == "‚úçÔ∏è Nh·∫≠p tay":
                company = st.text_input("T√™n c√¥ng ty:")
                liked_text = st.text_area("What I liked (√Ω ki·∫øn t√≠ch c·ª±c):")
                suggestion_text = st.text_area("Suggestions for improvement (g√≥p √Ω):")

                rating = st.slider("Rating", 1, 5, 3)
                salary = st.slider("Salary & benefits", 1, 5, 3)
                training = st.slider("Training & learning", 1, 5, 3)
                care = st.slider("Management cares about me", 1, 5, 3)
                culture = st.slider("Culture & fun", 1, 5, 3)
                office = st.slider("Office & workspace", 1, 5, 3)
                recommend = st.selectbox("Recommend?", ["Yes", "No"])

                combined_text = (liked_text or "") + " " + (suggestion_text or "")

                if st.button("üîç Ph√¢n t√≠ch c·∫£m x√∫c") and combined_text.strip():
                    X_input = vectorizer.transform([combined_text])

                    # D·ª± ƒëo√°n t·ª´ m√¥ h√¨nh
                    pred_xgb = label_encoder.inverse_transform(xgb_model.predict(X_input))[0]

                    st.success("‚úÖ K·∫øt qu·∫£ ph√¢n t√≠ch c·∫£m x√∫c:")
                    st.write(f"- **Sentiment:** {pred_xgb}")

                    summary_df = pd.DataFrame({
                        "Company": [company],
                        "What I liked": [liked_text],
                        "Suggestions for improvement": [suggestion_text],
                        "Rating": [rating],
                        "Salary": [salary],
                        "Training": [training],
                        "Care": [care],
                        "Culture": [culture],
                        "Office": [office],
                        "Recommend": [recommend],
                        "Sentiment": [pred_xgb]
                    })
                    st.write("### üßæ T·ªïng h·ª£p th√¥ng tin:")
                    st.dataframe(summary_df)

            elif input_method == "üìÅ T·∫£i file Excel":
                uploaded_file = st.file_uploader("T·∫£i file .xlsx ch·ª©a review", type="xlsx")

                if uploaded_file:
                    df_new = pd.read_excel(uploaded_file)
                    if ("What I liked" not in df_new.columns) or ("Suggestions for improvement" not in df_new.columns):
                        st.warning("‚ö†Ô∏è File c·∫ßn c√≥ c·ªôt 'What I liked' v√† 'Suggestions for improvement'")
                    else:
                        combined_col = df_new["What I liked"].fillna("") + " " + df_new["Suggestions for improvement"].fillna("")
                        X_new = vectorizer.transform(combined_col.astype(str))
                        df_new["Sentiment"] = label_encoder.inverse_transform(xgb_model.predict(X_new))
                        st.success("‚úÖ ƒê√£ ph√¢n t√≠ch xong!")
                        st.dataframe(df_new)
        
        except FileNotFoundError as e:
            st.error(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file model: {str(e)}")
            st.info("Vui l√≤ng ƒë·∫£m b·∫£o c√°c file model t·ªìn t·∫°i trong th∆∞ m·ª•c 'models/'")
        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói khi t·∫£i model: {str(e)}")
